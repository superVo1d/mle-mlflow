{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de15d08f-51f8-411e-a8c1-e7ff93742b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "# определяем глобальные переменные\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "YOUR_NAME = \"supervoid\" # введите своё имя для создания уникального эксперимента\n",
    "assert YOUR_NAME, \"введите своё имя в переменной YOUR_NAME для создания уникального эксперимента\"\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = f\"test_connection_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"test_connection_run\"\n",
    "\n",
    "# тестовые данные\n",
    "METRIC_NAME = \"test_metric\"\n",
    "METRIC_VALUE = 0\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# создаём тестовый эксперимент и записываем в него тестовую информацию\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    mlflow.log_metric(METRIC_NAME, METRIC_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9189e2e7-52db-4b47-b973-064ccbca84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. Проверяем себя, что в MLflow:\n",
    "# - создался `experiment` с нашим именем\n",
    "# - внутри эксперимента появился запуск `run`\n",
    "# - внутри `run` записалась наша тестовая `metric`\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "assert \"active\" == experiment.lifecycle_stage\n",
    "assert mlflow.get_run(run_id)\n",
    "assert METRIC_VALUE == run.data.metrics[METRIC_NAME] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9061c3-b9dd-46f5-b2b0-18c29674ab04",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m connection \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msslmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequire\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_session_attrs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread-write\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      2\u001b[0m postgres_credentials \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m([var_value \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(postgres_credentials\u001b[38;5;241m.\u001b[39mvalues())])\n\u001b[1;32m     11\u001b[0m connection\u001b[38;5;241m.\u001b[39mupdate(postgres_credentials)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# определим название таблицы, в которой хранятся наши данные.\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": \"\", \n",
    "    \"port\": \"\",\n",
    "    \"dbname\": \"\",\n",
    "    \"user\": \"\",\n",
    "    \"password\": \"\",\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d9e10-0a72-4455-a4d2-5e628f87f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_columns = [\n",
    "    \"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "    # посчитайте уникальные значения для колонок, где немного уникальных значений (переменная counts_columns)\n",
    "    column_stat = df[col].value_counts()\n",
    "    column_stat = {f\"{col}_{key}\": value for key, value in column_stat.items()}\n",
    "\n",
    "    # обновите словарь stats\n",
    "    stats.update(column_stat)\n",
    "\n",
    "\n",
    "stats[\"data_length\"] = df.shape[0]\n",
    "stats[\"monthly_charges_min\"] = df[\"monthly_charges\"].min()\n",
    "stats[\"monthly_charges_max\"] = df[\"monthly_charges\"].max() # посчитайте максимальное значение в колонке\n",
    "stats[\"monthly_charges_mean\"] = df[\"monthly_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"monthly_charges_median\"] = df[\"monthly_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"total_charges_min\"] = df[\"total_charges\"].min() # посчитайте минимальное значение в колонке\n",
    "stats[\"total_charges_max\"] = df[\"total_charges\"].max() # посчитайте максимальное значение в колонке\n",
    "stats[\"total_charges_mean\"] = df[\"total_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"total_charges_median\"] = df[\"total_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"unique_customers_number\"] = df[\"customer_id\"].nunique() # посчитайте кол-во уникальных id\n",
    "stats[\"end_date_nan\"] = df[\"end_date\"].isna().sum() # посчитайте кол-во пустых строк в колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640e51eb-a8d4-4bc0-bf25-ecfe4754a4c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id \u001b[38;5;66;03m# ваш код здесь\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# логируем метрики эксперимента\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# предполагается, что переменная stats содержит словарь с метриками,\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# где ключи — это названия метрик, а значения — числовые значения метрик\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics(\u001b[43mstats\u001b[49m) \u001b[38;5;66;03m# ваш код здесь\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fio:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# задаём название эксперимента и имя запуска для логирования в MLflow\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_fio\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "# создаём новый эксперимент в MLflow с указанным названием \n",
    "# если эксперимент с таким именем уже существует, \n",
    "# MLflow возвращает идентификатор существующего эксперимента\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME) # ваш код здесь\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id # ваш код здесь\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats) # ваш код здесь\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "        for index, column in enumerate(list(df)):\n",
    "            fio.write(column + (',' if index != len(list(df)) - 1 else ''))\n",
    "        \n",
    "    df.to_csv(\"users_churn.csv\", index=False) \n",
    "    \n",
    "    mlflow.log_artifact('columns.txt', 'dataframe')  # ваш код здесь\n",
    "    mlflow.log_artifact('users_churn.csv', 'dataframe') # ваш код здесь\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id) # ваш код здесь\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert 'FINISHED' == run.info.status\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n",
    "os.remove('columns.txt') # ваш код здесь\n",
    "os.remove('users_churn.csv') # ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8e47f7-6c77-458c-aebd-c8622a948a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caafcb8-99d0-4f5d-ac8a-0998c4a9532e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
